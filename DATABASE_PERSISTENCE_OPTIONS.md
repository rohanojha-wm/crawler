# Database Persistence Options for GitHub Actions

This document explains how to implement persistent SQLite database storage in GitHub Actions to maintain historical monitoring data between workflow runs.

## ğŸ¯ **Why Persistent Database?**

### **Current Limitations (Stateless):**
- âŒ No historical data between runs
- âŒ No trending analysis 
- âŒ No long-term performance insights
- âŒ Each run starts fresh

### **Benefits of Persistent Database:**
- âœ… **Historical Analytics**: Trend analysis over weeks/months
- âœ… **Rich Dashboard**: Same data as local Flask app
- âœ… **Performance Tracking**: Response time trends
- âœ… **Reliability Metrics**: Long-term success rates
- âœ… **Drill-Down Capability**: Group â†’ Country â†’ Individual requests

## ğŸ”§ **Implementation Options**

### **Option 1: Artifact-Based Persistence** â­ **RECOMMENDED**

**Files:**
- `.github/workflows/url-monitor-persistent.yml`
- `ci_monitor_persistent.py` 
- `generate_historical_report.py`

**How it works:**
```
Run #1: Create new database â†’ Save as artifact
Run #2: Download artifact â†’ Update database â†’ Save updated artifact  
Run #3: Download artifact â†’ Update database â†’ Save updated artifact
```

**Pros:**
- âœ… Simple implementation
- âœ… No repository bloat
- âœ… Fast downloads (artifacts are cached)
- âœ… Automatic cleanup after 90 days
- âœ… No git conflicts

**Cons:**
- âš ï¸ 90-day maximum retention
- âš ï¸ Lost if artifacts are manually deleted

**Setup:**
```bash
# Replace existing workflow
cp .github/workflows/url-monitor-persistent.yml .github/workflows/url-monitor.yml

# The scripts will automatically handle database persistence
git add .
git commit -m "Enable persistent database monitoring"
git push
```

### **Option 2: Git Repository Persistence**

**Files:**
- `.github/workflows/url-monitor-git-persistence.yml`
- `ci_monitor_persistent.py`
- `generate_historical_report.py`

**How it works:**
```
Run #1: Create database â†’ Commit to repository
Run #2: Pull latest â†’ Update database â†’ Commit changes
Run #3: Pull latest â†’ Update database â†’ Commit changes
```

**Pros:**
- âœ… Permanent persistence (never expires)
- âœ… Version controlled database history
- âœ… Always available with repository
- âœ… Can track database changes over time

**Cons:**
- âš ï¸ Repository size grows over time
- âš ï¸ Binary files not ideal for git
- âš ï¸ Potential merge conflicts
- âš ï¸ Every run creates a commit

**Setup:**
```bash
# Use git-based workflow
cp .github/workflows/url-monitor-git-persistence.yml .github/workflows/url-monitor.yml

# Add database to gitignore initially (will be managed by workflow)
echo "monitoring.db" >> .gitignore

git add .
git commit -m "Enable git-persistent database monitoring"
git push
```

### **Option 3: External Database** (Advanced)

**Services:**
- AWS RDS (PostgreSQL/MySQL)
- Google Cloud SQL  
- Azure SQL Database
- PlanetScale (MySQL)
- Supabase (PostgreSQL)

**How it works:**
```
Run #1: Connect to cloud database â†’ Insert results
Run #2: Connect to cloud database â†’ Insert results  
Run #3: Connect to cloud database â†’ Insert results
```

**Pros:**
- âœ… Professional database hosting
- âœ… Unlimited retention
- âœ… Advanced querying capabilities
- âœ… Scalable and reliable
- âœ… No repository impact

**Cons:**
- âš ï¸ Monthly costs ($5-50+)
- âš ï¸ Complex setup
- âš ï¸ Requires credentials management
- âš ï¸ Network dependencies

## ğŸ“Š **Comparison Matrix**

| Feature | Artifacts | Git Repo | External DB |
|---------|-----------|----------|-------------|
| **Setup Complexity** | ğŸŸ¢ Simple | ğŸŸ¡ Medium | ğŸ”´ Complex |
| **Cost** | ğŸŸ¢ Free | ğŸŸ¢ Free | ğŸ”´ $5-50/month |
| **Retention** | ğŸŸ¡ 90 days | ğŸŸ¢ Forever | ğŸŸ¢ Forever |
| **Repository Impact** | ğŸŸ¢ None | ğŸ”´ Grows over time | ğŸŸ¢ None |
| **Reliability** | ğŸŸ¡ Good | ğŸŸ¢ Excellent | ğŸŸ¢ Excellent |
| **Performance** | ğŸŸ¢ Fast | ğŸŸ¡ Medium | ğŸŸ¡ Network dependent |
| **Data Portability** | ğŸŸ¡ GitHub only | ğŸŸ¢ With repo | ğŸŸ¡ Service dependent |

## ğŸš€ **Quick Implementation Guide**

### **Step 1: Choose Your Approach**

**For most users:** Use **Artifact-Based Persistence** (Option 1)

### **Step 2: Install Files**

The following files are already created for you:
- âœ… `ci_monitor_persistent.py` - Uses same database schema as Flask app
- âœ… `generate_historical_report.py` - Creates rich historical reports
- âœ… `url-monitor-persistent.yml` - Artifact-based workflow
- âœ… `url-monitor-git-persistence.yml` - Git-based workflow

### **Step 3: Enable Persistent Monitoring**

```bash
# Option 1: Artifact-based (RECOMMENDED)
cp .github/workflows/url-monitor-persistent.yml .github/workflows/url-monitor.yml

# Option 2: Git-based  
cp .github/workflows/url-monitor-git-persistence.yml .github/workflows/url-monitor.yml

# Commit and push
git add .
git commit -m "ğŸš€ Enable persistent database monitoring"
git push
```

### **Step 4: Verify It's Working**

1. **Check Workflow Runs**: Go to your repository â†’ Actions tab
2. **Look for Database Messages**: Logs should show "Found existing database" after first run
3. **View Enhanced Reports**: GitHub Pages will show historical data
4. **Check Artifacts**: Artifacts section should contain `monitoring-database`

## ğŸ“ˆ **What You Get with Persistent Database**

### **Enhanced GitHub Pages Reports:**
- ğŸ“Š **Historical Trends**: 1h, 3h, 1d, 7d, 30d comparisons
- ğŸ“ˆ **Group Statistics**: Success rates by group over time
- ğŸŒ **Country Analysis**: Performance by geographic region
- ğŸ“‰ **Failure Tracking**: Detailed failure history and patterns

### **Rich Data Analysis:**
```sql
-- Examples of what becomes possible:
SELECT AVG(success_rate) FROM daily_stats WHERE group_name = 'Production';
SELECT response_time_trend FROM weekly_analysis WHERE country_code = 'US';
SELECT failure_patterns FROM historical_failures WHERE url LIKE '%api%';
```

### **Professional Monitoring:**
- ğŸ”„ **Continuous History**: Never lose monitoring data
- ğŸ“Š **Business Intelligence**: Long-term trend analysis
- ğŸš¨ **Smart Alerting**: Context-aware failure detection
- ğŸ“ˆ **Performance Insights**: Response time optimization

## ğŸ” **Monitoring Database Growth**

### **Artifact Method:**
```bash
# Database size is shown in workflow logs
# Typical growth: ~1-2KB per monitoring run
# 30-day estimate: ~1-2MB for 15 URLs monitored every 30 minutes
```

### **Git Method:**
```bash
# Check repository size impact
git ls-files -s monitoring.db

# Monitor growth over time
git log --oneline --grep="Update monitoring database"
```

## ğŸ› ï¸ **Troubleshooting**

### **Common Issues:**

#### **"No database found" on second run:**
```bash
# Check artifact retention in workflow
retention-days: 90  # Make sure this is set

# Verify artifact upload/download steps
- name: Upload updated database
- name: Download previous database
```

#### **Database corruption:**
```bash
# Manual reset (will lose historical data)
# Delete the artifact in GitHub UI or wait for natural expiration
```

#### **Repository too large (Git method):**
```bash
# Switch to artifact method
cp .github/workflows/url-monitor-persistent.yml .github/workflows/url-monitor.yml

# Remove database from git
git rm monitoring.db
git commit -m "Switch to artifact-based persistence"
```

## ğŸ‰ **Success Metrics**

After implementing persistent database, you should see:

âœ… **"Found existing database"** in workflow logs (after first run)
âœ… **Historical data** in GitHub Pages reports  
âœ… **Trend charts** showing data over multiple time periods
âœ… **Database artifacts** or **commits** (depending on method chosen)
âœ… **Enhanced failure analysis** with historical context

## ğŸ”„ **Migration Path**

### **From Stateless to Persistent:**
1. Keep existing workflow running
2. Deploy persistent workflow alongside
3. Verify persistent workflow works
4. Replace original workflow
5. Remove old stateless files

### **Between Persistence Methods:**
```bash
# Artifact â†’ Git
# Download latest artifact, commit as initial database

# Git â†’ Artifact  
# Extract database from git, upload as initial artifact

# Any â†’ External
# Export SQLite data, import to cloud database
```

Your monitoring system now has enterprise-grade persistence capabilities! ğŸ‰

## ğŸ“ **Need Help?**

Check the workflow logs for detailed information:
- Database size and status
- Artifact upload/download success
- Historical data generation
- Report deployment status
