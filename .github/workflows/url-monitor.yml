name: URL Monitoring with Persistent Database

on:
  schedule:
    # Run every 30 minutes
    - cron: '*/30 * * * *'
  workflow_dispatch: # Allow manual triggering
  push:
    branches: [ main ]
    paths:
      - 'urls.csv'
      - '.github/workflows/url-monitor-persistent.yml'

# Security: Explicit permissions for the workflow
permissions:
  contents: read      # To checkout repository
  actions: write      # To upload/download artifacts (database persistence)
  pages: write        # To deploy to GitHub Pages
  id-token: write     # For GitHub Pages deployment
  issues: write       # To create issues on monitoring failures

jobs:
  monitor-urls-persistent:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    # Option 1: Download previous database from artifacts
    - name: Download previous database
      uses: actions/download-artifact@v4
      with:
        name: monitoring-database
        path: .
      continue-on-error: true  # Continue if no previous database exists
    
    - name: Check if database exists
      run: |
        if [ -f monitoring.db ]; then
          echo "Found existing database ($(stat -c%s monitoring.db) bytes)"
          echo "DATABASE_EXISTS=true" >> $GITHUB_ENV
        else
          echo "No existing database found, will create new one"
          echo "DATABASE_EXISTS=false" >> $GITHUB_ENV
        fi
    
    - name: Run URL monitoring with persistent database
      run: python ci_monitor_persistent.py
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        DATABASE_EXISTS: ${{ env.DATABASE_EXISTS }}
    
    # Save updated database as artifact for next run
    - name: Upload updated database
      uses: actions/upload-artifact@v4
      with:
        name: monitoring-database
        path: monitoring.db
        retention-days: 90  # Keep for 90 days (maximum)
    
    - name: Create results directory
      run: mkdir -p monitoring-results
    
    - name: Generate comprehensive report with historical data
      run: python generate_persistent_report.py
    
    - name: Upload monitoring results
      uses: actions/upload-artifact@v4
      with:
        name: monitoring-results-${{ github.run_number }}
        path: monitoring-results/
        retention-days: 30
    
    - name: Create Issue on Failures
      if: failure()
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = 'monitoring-results/failures.json';
          
          if (fs.existsSync(path)) {
            const failures = JSON.parse(fs.readFileSync(path, 'utf8'));
            const body = `## URL Monitoring Failures - ${new Date().toISOString()}
            
            The following URLs failed during monitoring:
            
            ${failures.map(f => `- **${f.url}** (${f.group_name}): ${f.error_message || 'Status ' + f.status_code}`).join('\n')}
            
            **Historical Context**: This monitoring run includes ${failures.length > 0 ? 'persistent' : 'no'} database history.
            **Run:** ${context.payload.repository.html_url}/actions/runs/${context.runId}
            `;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `URL Monitoring Failures - ${new Date().toLocaleDateString()}`,
              body: body,
              labels: ['monitoring', 'alert', 'persistent-db']
            });
          }

  generate-historical-report:
    runs-on: ubuntu-latest
    needs: monitor-urls-persistent
    if: always()
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: pip install -r requirements.txt
    
    - name: Download updated database
      uses: actions/download-artifact@v4
      with:
        name: monitoring-database
        path: .
      continue-on-error: true
    
    - name: Download monitoring results
      uses: actions/download-artifact@v4
      with:
        name: monitoring-results-${{ github.run_number }}
        path: monitoring-results/
    
    - name: Generate comprehensive historical report
      run: |
        python generate_historical_report.py
    
    - name: Deploy to GitHub Pages
      if: github.ref == 'refs/heads/main'
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./monitoring-results
        destination_dir: reports
    
    - name: Send enhanced Slack notification
      if: env.SLACK_WEBHOOK_URL != ''
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ job.status }}
        custom_payload: |
          {
            "text": "URL Monitoring Report with Historical Data",
            "attachments": [{
              "color": "${{ job.status == 'success' && 'good' || 'danger' }}",
              "title": "Historical Monitoring Results - ${{ github.run_number }}",
              "title_link": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "fields": [{
                "title": "Status",
                "value": "${{ job.status }}",
                "short": true
              }, {
                "title": "Database",
                "value": "Persistent SQLite",
                "short": true
              }, {
                "title": "Repository",
                "value": "${{ github.repository }}",
                "short": true
              }]
            }]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
